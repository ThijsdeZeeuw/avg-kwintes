#!/usr/bin/env python3
"""
start_services.py

This script starts the Supabase stack first, waits for it to initialize, and then starts
the local AI stack. Both stacks use the same Docker Compose project name ("localai")
so they appear together in Docker Desktop.
"""

import os
import subprocess
import shutil
import time
import argparse
import platform
import sys
import secrets
import string
import re

def generate_random_string(length=32):
    """Generate a random string of specified length."""
    alphabet = string.ascii_letters + string.digits
    return ''.join(secrets.choice(alphabet) for _ in range(length))

def save_secrets_to_file(env_vars):
    """Save all secrets and sensitive information to secrets.txt."""
    secrets_file = 'secrets.txt'
    sensitive_keys = [
        'N8N_ENCRYPTION_KEY',
        'N8N_USER_MANAGEMENT_JWT_SECRET',
        'POSTGRES_PASSWORD',
        'JWT_SECRET',
        'ANON_KEY',
        'SERVICE_ROLE_KEY',
        'DASHBOARD_PASSWORD',
        'FLOWISE_PASSWORD',
        'GRAFANA_ADMIN_PASS'
    ]
    
    with open(secrets_file, 'w') as f:
        f.write("=== Local AI Stack Secrets ===\n")
        f.write("Generated on: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n\n")
        
        for key in sensitive_keys:
            if key in env_vars:
                f.write(f"{key}={env_vars[key]}\n")
        
        f.write("\n=== Service URLs ===\n")
        domain = env_vars.get('DOMAIN_NAME', 'kwintes.cloud')
        f.write(f"n8n: https://{env_vars.get('N8N_HOSTNAME', f'n8n.{domain}')}\n")
        f.write(f"Supabase: https://{env_vars.get('SUPABASE_HOSTNAME', f'supabase.{domain}')}\n")
        f.write(f"Flowise: https://{env_vars.get('FLOWISE_HOSTNAME', f'flowise.{domain}')}\n")
        f.write(f"Grafana: https://grafana.{domain}\n")
        f.write(f"Prometheus: https://prometheus.{domain}\n")
        f.write(f"Whisper API: https://whisper.{domain}\n")
        f.write(f"Qdrant API: https://qdrant.{domain}\n")
        
        f.write("\n=== Default Credentials ===\n")
        f.write(f"Grafana: {env_vars.get('GRAFANA_ADMIN_USER', 'admin')} / {env_vars.get('GRAFANA_ADMIN_PASS', '')}\n")
        f.write(f"Flowise: {env_vars.get('FLOWISE_USERNAME', 'admin')} / {env_vars.get('FLOWISE_PASSWORD', '')}\n")
        f.write(f"Supabase Dashboard: {env_vars.get('DASHBOARD_USERNAME', 'supabase')} / {env_vars.get('DASHBOARD_PASSWORD', '')}\n")
    
    print(f"\nSecrets have been saved to {secrets_file}")
    print("IMPORTANT: Keep this file secure and do not commit it to version control!")

def create_env_from_example():
    """Create .env file from .env.example with user instructions."""
    env_example_path = '.env.example'
    env_path = '.env'
    
    if not os.path.exists(env_example_path):
        print(f"Error: {env_example_path} not found. Please create it first.")
        return False
    
    if os.path.exists(env_path):
        overwrite = input(f"\n{env_path} already exists. Overwrite? (y/n): ").lower()
        if overwrite != 'y':
            print(f"Using existing {env_path} file.")
            return True
    
    # Load default values from .env.example
    default_values = {}
    with open(env_example_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                default_values[key.strip()] = value.strip()
    
    # Create a new .env file with the default values
    with open(env_path, 'w') as f:
        f.write("# This file was generated by start_services.py\n")
        f.write("# Default values are taken from .env.example\n\n")
        
        for key, value in default_values.items():
            f.write(f"{key}={value}\n")
    
    print(f"\n=== Environment Setup ===")
    print(f"A copy of {env_example_path} has been made as {env_path}")
    print("IMPORTANT: Please edit this file and update the following values:")
    print("  1. N8N_ENCRYPTION_KEY and N8N_USER_MANAGEMENT_JWT_SECRET with secure random strings")
    print("  2. All Supabase configuration values (POSTGRES_PASSWORD, JWT_SECRET, etc.)")
    print("  3. Set your domain in *_HOSTNAME variables and LETSENCRYPT_EMAIL")
    print("\nAfter updating these values, run this script again.")
    
    # Ask user if they want to edit the file now
    edit_now = input("\nWould you like to edit .env file now? (y/n): ").lower()
    if edit_now == 'y':
        # Try to open with default editor
        try:
            if platform.system() == 'Windows':
                os.system(f"notepad {env_path}")
            elif platform.system() == 'Darwin':  # macOS
                os.system(f"open {env_path}")
            else:  # Linux and others
                editor = os.environ.get('EDITOR', 'nano')
                os.system(f"{editor} {env_path}")
        except Exception as e:
            print(f"Error opening editor: {e}")
            print(f"Please edit {env_path} manually.")
    
    return True

def create_interactive_env():
    """Create .env file interactively with user input."""
    print("\n=== Interactive Environment Setup ===")
    
    env_example_path = '.env.example'
    
    # Load default values from .env.example if it exists
    default_values = {}
    if os.path.exists(env_example_path):
        with open(env_example_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    default_values[key.strip()] = value.strip()
        print("Loaded default values from .env.example")
    
    # Add generated values for keys that need them
    env_vars = {
        # n8n Configuration
        'N8N_ENCRYPTION_KEY': default_values.get('N8N_ENCRYPTION_KEY', generate_random_string(32)),
        'N8N_USER_MANAGEMENT_JWT_SECRET': default_values.get('N8N_USER_MANAGEMENT_JWT_SECRET', generate_random_string(32)),
        
        # n8n domain settings
        'N8N_HOST': default_values.get('N8N_HOST', 'n8n.kwintes.cloud'),
        'N8N_PROTOCOL': default_values.get('N8N_PROTOCOL', 'https'),
        'N8N_PORT': default_values.get('N8N_PORT', '8008'),
        'N8N_EDITOR_BASE_URL': default_values.get('N8N_EDITOR_BASE_URL', 'https://n8n.kwintes.cloud'),
        
        # Supabase Configuration
        'POSTGRES_PASSWORD': default_values.get('POSTGRES_PASSWORD', generate_random_string(16)),
        'JWT_SECRET': default_values.get('JWT_SECRET', generate_random_string(32)),
        'ANON_KEY': default_values.get('ANON_KEY', generate_random_string(32)),
        'SERVICE_ROLE_KEY': default_values.get('SERVICE_ROLE_KEY', generate_random_string(32)),
        'DASHBOARD_USERNAME': default_values.get('DASHBOARD_USERNAME', 'supabase'),
        'DASHBOARD_PASSWORD': default_values.get('DASHBOARD_PASSWORD', generate_random_string(16)),
        'POOLER_TENANT_ID': default_values.get('POOLER_TENANT_ID', '1001'),
        'POSTGRES_HOST': default_values.get('POSTGRES_HOST', 'db'),
        'POSTGRES_DB': default_values.get('POSTGRES_DB', 'postgres'),
        'POSTGRES_PORT': default_values.get('POSTGRES_PORT', '5432'),
        
        # URL Settings
        'DOMAIN_NAME': default_values.get('DOMAIN_NAME', 'kwintes.cloud'),
        'SUBDOMAIN': default_values.get('SUBDOMAIN', 'n8n'),
        'N8N_HOSTNAME': default_values.get('N8N_HOSTNAME', 'n8n.kwintes.cloud'),
        'WEBUI_HOSTNAME': default_values.get('WEBUI_HOSTNAME', 'openwebui.kwintes.cloud'),
        'FLOWISE_HOSTNAME': default_values.get('FLOWISE_HOSTNAME', 'flowise.kwintes.cloud'),
        'SUPABASE_HOSTNAME': default_values.get('SUPABASE_HOSTNAME', 'supabase.kwintes.cloud'),
        'OLLAMA_HOSTNAME': default_values.get('OLLAMA_HOSTNAME', 'ollama.kwintes.cloud'),
        'SEARXNG_HOSTNAME': default_values.get('SEARXNG_HOSTNAME', 'searxng.kwintes.cloud'),
        'LETSENCRYPT_EMAIL': default_values.get('LETSENCRYPT_EMAIL', 'admin@kwintes.cloud'),
        
        # Flowise Configuration
        'FLOWISE_USERNAME': default_values.get('FLOWISE_USERNAME', 'admin'),
        'FLOWISE_PASSWORD': default_values.get('FLOWISE_PASSWORD', generate_random_string(12)),
        'ENABLE_METRICS': default_values.get('ENABLE_METRICS', 'true'),
        'METRICS_PROVIDER': default_values.get('METRICS_PROVIDER', 'prometheus'),
        'METRICS_INCLUDE_NODE_METRICS': default_values.get('METRICS_INCLUDE_NODE_METRICS', 'true'),
        
        # Qdrant Configuration
        'QDRANT_HOST': default_values.get('QDRANT_HOST', 'qdrant'),
        'QDRANT_PORT': default_values.get('QDRANT_PORT', '6333'),
        
        # Monitoring Configuration
        'PROMETHEUS_PORT': default_values.get('PROMETHEUS_PORT', '9090'),
        'GRAFANA_PORT': default_values.get('GRAFANA_PORT', '3005'),
        'GRAFANA_ADMIN_USER': default_values.get('GRAFANA_ADMIN_USER', 'admin'),
        'GRAFANA_ADMIN_PASS': default_values.get('GRAFANA_ADMIN_PASS', generate_random_string(16)),
        'DATA_FOLDER': default_values.get('DATA_FOLDER', './data'),
        
        # System Configuration
        'TZ': default_values.get('TZ', 'Germany/Berlin'),
        'LANG': default_values.get('LANG', 'en_US.UTF-8'),
        'LC_ALL': default_values.get('LC_ALL', 'en_US.UTF-8'),
        
        # Python Configuration
        'PYTHON_PATH': default_values.get('PYTHON_PATH', '/usr/bin/python3')
    }
    
    # Import any other values from .env.example that weren't explicitly included above
    for key, value in default_values.items():
        if key not in env_vars:
            env_vars[key] = value
    
    # Interactive prompts for critical values
    print("\nPlease enter the following values (press Enter to use defaults):")
    
    critical_vars = [
        'DOMAIN_NAME',
        'SUBDOMAIN',
        'N8N_HOST',
        'N8N_HOSTNAME',
        'SUPABASE_HOSTNAME',
        'LETSENCRYPT_EMAIL',
        'FLOWISE_USERNAME',
        'FLOWISE_PASSWORD',
        'GRAFANA_ADMIN_USER',
        'GRAFANA_ADMIN_PASS',
        'TZ',
        'DASHBOARD_PASSWORD'
    ]
    
    for var in critical_vars:
        default = env_vars[var]
        value = input(f"{var} [{default}]: ").strip()
        if value:
            env_vars[var] = value
    
    # Write to .env file
    with open('.env', 'w') as f:
        f.write("# This file was generated by start_services.py\n")
        f.write("# Default values are taken from .env.example\n\n")
        for key, value in env_vars.items():
            f.write(f"{key}={value}\n")
    
    # Save secrets to secrets.txt
    save_secrets_to_file(env_vars)
    
    print("\n.env file created successfully!")
    print("IMPORTANT: Check secrets.txt for all sensitive information!")
    return True

def initialize_monitoring():
    """Initialize monitoring services and create necessary configurations."""
    print("\n=== Initializing Monitoring Services ===")
    
    # Create Prometheus configuration if it doesn't exist
    if not os.path.exists('prometheus.yml'):
        with open('prometheus.yml', 'w') as f:
            f.write('''global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
  - job_name: 'n8n'
    static_configs:
      - targets: ['n8n:8000']
    metrics_path: '/metrics'
  - job_name: 'qdrant'
    static_configs:
      - targets: ['qdrant:6333']
    metrics_path: '/metrics'
  - job_name: 'whisper'
    static_configs:
      - targets: ['whisper:9000']
    metrics_path: '/metrics'
  - job_name: 'ollama'
    static_configs:
      - targets: ['ollama:11434']
    metrics_path: '/metrics'
''')
        print("Created prometheus.yml")

def run_command(cmd, cwd=None):
    """Run a shell command and print it."""
    print("Running:", " ".join(cmd))
    subprocess.run(cmd, cwd=cwd, check=True)

def clone_supabase_repo():
    """Clone the Supabase repository using sparse checkout if not already present."""
    if not os.path.exists("supabase"):
        print("Cloning the Supabase repository...")
        run_command([
            "git", "clone", "--filter=blob:none", "--no-checkout",
            "https://github.com/supabase/supabase.git"
        ])
        os.chdir("supabase")
        run_command(["git", "sparse-checkout", "init", "--cone"])
        run_command(["git", "sparse-checkout", "set", "docker"])
        run_command(["git", "checkout", "master"])
        os.chdir("..")
    else:
        print("Supabase repository already exists, updating...")
        os.chdir("supabase")
        run_command(["git", "pull"])
        os.chdir("..")

def prepare_supabase_env():
    """Copy .env to .env in supabase/docker."""
    if not os.path.exists('.env'):
        print("Error: .env file not found. Please create it first.")
        return False
        
    env_path = os.path.join("supabase", "docker", ".env")
    src_env_path = os.path.join(".env")
    
    # Make sure the target directory exists
    os.makedirs(os.path.dirname(env_path), exist_ok=True)
    
    print("Copying .env in root to .env in supabase/docker...")
    shutil.copyfile(src_env_path, env_path)
    
    print("Supabase environment prepared successfully.")
    return True

def check_docker_compose():
    """Check if 'docker compose' or 'docker-compose' should be used."""
    # Special handling for Ubuntu 24.04
    try:
        # Check if this is Ubuntu 24.04
        with open('/etc/os-release', 'r') as f:
            os_info = f.read()
            if 'VERSION="24.04"' in os_info and 'Ubuntu' in os_info:
                print("Detected Ubuntu 24.04 - using docker-compose...")
                # For Ubuntu 24.04, directly use docker-compose if it exists
                if os.path.exists('/usr/local/bin/docker-compose'):
                    return ['/usr/local/bin/docker-compose']
                elif subprocess.run(["which", "docker-compose"], capture_output=True, text=True).returncode == 0:
                    return ["docker-compose"]
                else:
                    # Try to install docker-compose automatically
                    try:
                        print("Attempting to install docker-compose...")
                        install_cmd = [
                            "curl", "-L", 
                            "https://github.com/docker/compose/releases/download/v2.24.5/docker-compose-linux-x86_64", 
                            "-o", "/usr/local/bin/docker-compose"
                        ]
                        subprocess.run(install_cmd, check=True)
                        subprocess.run(["chmod", "+x", "/usr/local/bin/docker-compose"], check=True)
                        print("Successfully installed docker-compose")
                        return ["/usr/local/bin/docker-compose"]
                    except subprocess.CalledProcessError as e:
                        print(f"Error installing docker-compose: {e}")
                        print("Please install docker-compose manually")
                        sys.exit(1)
    except FileNotFoundError:
        # Not a Linux system or /etc/os-release doesn't exist
        pass
    except Exception as e:
        print(f"Warning: Error checking OS version: {e}")
    
    # Regular detection process for other systems
    try:
        # Check if 'docker compose' is available (Docker CLI plugin)
        subprocess.run(["docker", "compose", "version"], 
                       capture_output=True, check=True)
        return ["docker", "compose"]
    except subprocess.CalledProcessError:
        # Fall back to 'docker-compose' command
        try:
            subprocess.run(["docker-compose", "--version"], 
                           capture_output=True, check=True)
            return ["docker-compose"]
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("Error: Neither 'docker compose' nor 'docker-compose' is available.")
            print("Please install Docker Compose: https://docs.docker.com/compose/install/")
            sys.exit(1)

def stop_existing_containers():
    """Stop and remove existing containers for our unified project ('localai')."""
    print("Stopping and removing existing containers for the unified project 'localai'...")
    docker_compose_cmd = check_docker_compose()
    cmd = docker_compose_cmd + [
        "-p", "localai",
        "-f", "docker-compose.yml",
        "-f", "supabase/docker/docker-compose.yml",
        "down"
    ]
    run_command(cmd)

def start_supabase():
    """Start the Supabase services (using its compose file)."""
    print("Starting Supabase services...")
    docker_compose_cmd = check_docker_compose()
    cmd = docker_compose_cmd + [
        "-p", "localai", 
        "-f", "supabase/docker/docker-compose.yml", 
        "up", "-d"
    ]
    run_command(cmd)

def start_local_ai(profile=None):
    """Start all local AI services using docker-compose"""
    print(f"Starting Local AI stack with profile: {profile or 'default'}")
    check_docker_compose()
    
    # Create n8n backup directories if they don't exist
    os.makedirs("n8n/backup/workflows", exist_ok=True)
    os.makedirs("n8n/backup/credentials", exist_ok=True)
    
    # Create shared data directory
    os.makedirs("shared", exist_ok=True)
    
    # Check and fix docker-compose.yml for SearXNG if needed
    generate_searxng_secret_key()
    
    # First stop running containers
    print("Stopping any existing containers...")
    stop_existing_containers()
    
    # Detect if we're on Ubuntu 24.04
    is_ubuntu_24_04 = False
    try:
        with open('/etc/os-release', 'r') as f:
            if 'VERSION_ID="24.04"' in f.read() and 'NAME="Ubuntu"' in f.read():
                is_ubuntu_24_04 = True
    except FileNotFoundError:
        pass
    
    if USE_DOCKER_COMPOSE_PLUGIN:
        if profile:
            cmd = ["docker", "compose", "-p", "localai", "--profile", profile, "-f", "docker-compose.yml", "up", "-d"]
        else:
            cmd = ["docker", "compose", "-p", "localai", "-f", "docker-compose.yml", "up", "-d"]
    elif is_ubuntu_24_04:
        # Use standalone docker-compose on Ubuntu 24.04
        if profile:
            cmd = ["/usr/local/bin/docker-compose", "-p", "localai", "--profile", profile, "-f", "docker-compose.yml", "up", "-d"]
        else:
            cmd = ["/usr/local/bin/docker-compose", "-p", "localai", "-f", "docker-compose.yml", "up", "-d"]
    else:
        if profile:
            cmd = ["docker-compose", "-p", "localai", "--profile", profile, "-f", "docker-compose.yml", "up", "-d"]
        else:
            cmd = ["docker-compose", "-p", "localai", "-f", "docker-compose.yml", "up", "-d"]
    
    print(f"Running command: {' '.join(cmd)}")
    try:
        run_command(cmd)
    except subprocess.CalledProcessError as e:
        print(f"Warning: Container startup had errors but continuing anyway: {str(e)}")
        # Check if n8n is running despite the error
        check_cmd = ["docker", "ps", "--filter", "name=n8n", "--format", "{{.Names}}"]
        result = subprocess.run(check_cmd, capture_output=True, text=True)
        if "n8n" not in result.stdout:
            print("Error: n8n container failed to start. Check docker logs for details.")
            # Try to start just the n8n container
            try:
                if USE_DOCKER_COMPOSE_PLUGIN:
                    retry_cmd = ["docker", "compose", "-p", "localai", "-f", "docker-compose.yml", "up", "-d", "n8n"]
                elif is_ubuntu_24_04:
                    retry_cmd = ["/usr/local/bin/docker-compose", "-p", "localai", "-f", "docker-compose.yml", "up", "-d", "n8n"]
                else:
                    retry_cmd = ["docker-compose", "-p", "localai", "-f", "docker-compose.yml", "up", "-d", "n8n"]
                print(f"Trying to start n8n container separately: {' '.join(retry_cmd)}")
                subprocess.run(retry_cmd, check=True)
            except subprocess.CalledProcessError:
                print("Failed to start n8n container separately.")
        else:
            print("n8n container is running despite errors in other services.")

    print("\nLocal AI stack started successfully.")
    print("\nAccess the services at:")
    print("- n8n: http://localhost:5678")
    print("- Flowise: http://localhost:3001")
    print("- OpenWebUI: http://localhost:8080")
    print("- Qdrant: http://localhost:6333")
    print("- Prometheus: http://localhost:9090")
    print("- Grafana: http://localhost:3000")
    print("- Ollama: http://localhost:11434")

def generate_searxng_secret_key():
    """Generate a random secret key for SearXNG if it doesn't exist"""
    # Skip if SearXNG is no longer in use
    if not os.path.exists('searxng'):
        print("SearXNG not found, skipping secret key generation")
        return
        
    searxng_dir = os.path.join(os.getcwd(), 'searxng')
    os.makedirs(searxng_dir, exist_ok=True)
    settings_base_path = os.path.join(searxng_dir, 'settings-base.yml')
    settings_path = os.path.join(searxng_dir, 'settings.yml')
    
    if not os.path.exists(settings_path):
        print("Generating SearXNG settings.yml with secure secret key...")
        
        # Default base settings if settings-base.yml doesn't exist
        default_settings = """# see https://docs.searxng.org/admin/settings/settings.html#settings-use-default-settings
use_default_settings: true
server:
  # base_url is defined in the SEARXNG_BASE_URL environment variable, see .env and docker-compose.yml
  secret_key: "ultrasecretkey"  # change this!
  limiter: false
  image_proxy: true
ui:
  static_use_hash: true
redis:
  url: redis://redis:6379/0
search:
    formats:
        - html
        - json
"""
        
        if not os.path.exists(settings_base_path):
            with open(settings_base_path, 'w') as f:
                f.write(default_settings)
        
        # Read the base settings
        with open(settings_base_path, 'r') as f:
            settings_content = f.read()
        
        # Generate a secure random key
        secret_key = generate_random_string(32)
        
        # Replace the placeholder with the secure key
        settings_content = settings_content.replace('ultrasecretkey', secret_key)
        
        # Write the new settings file
        with open(settings_path, 'w') as f:
            f.write(settings_content)
        
        print("SearXNG settings.yml created with secure secret key.")
    
    # Create uwsgi.ini if it doesn't exist
    uwsgi_path = os.path.join(searxng_dir, 'uwsgi.ini')
    if not os.path.exists(uwsgi_path):
        uwsgi_content = """[uwsgi]
# disable logging for privacy
disable-logging = true

# Number of workers (usually CPU count)
workers = %s

# Number of threads per worker
threads = %s

master = true
module = searx.webapp
"""
        uwsgi_workers = os.environ.get("SEARXNG_UWSGI_WORKERS", "4")
        uwsgi_threads = os.environ.get("SEARXNG_UWSGI_THREADS", "4")
        
        with open(uwsgi_path, 'w') as f:
            f.write(uwsgi_content % (uwsgi_workers, uwsgi_threads))

def check_and_fix_docker_compose_for_searxng():
    """Check and fix the docker-compose.yml file for SearXNG service"""
    # Skip if SearXNG is no longer in use
    if not os.path.exists('searxng'):
        print("SearXNG not found, skipping docker-compose check")
        return
        
    # Check if the docker-compose.yml file exists
    if not os.path.exists('docker-compose.yml'):
        print("docker-compose.yml file not found! Please make sure it exists in the current directory.")
        return

    # Read the docker-compose.yml file
    with open('docker-compose.yml', 'r') as f:
        docker_compose_content = f.read()

    # Check if the searxng service is present
    if 'container_name: searxng' not in docker_compose_content:
        print("SearXNG service not found in docker-compose.yml, no need to fix.")
        return

    # Check if the fix is already applied
    if "uwsgi.ini:/etc/uwsgi/searxng.ini:ro" in docker_compose_content:
        print("SearXNG docker-compose configuration already fixed.")
        return

    print("Fixing SearXNG configuration in docker-compose.yml...")

    # Fix the volumes section of the searxng service
    pattern = r'(searxng:\s+.*?volumes:\s+.*?- \./searxng:/etc/searxng:rw)(\s+.*?environment:)'
    replacement = r'\1\n      - ./searxng/uwsgi.ini:/etc/uwsgi/searxng.ini:ro\2'
    
    fixed_content = re.sub(pattern, replacement, docker_compose_content, flags=re.DOTALL)

    # Write the fixed content back to the file
    with open('docker-compose.yml', 'w') as f:
        f.write(fixed_content)

    print("SearXNG configuration in docker-compose.yml has been fixed.")

def create_data_directories():
    """Create necessary data directories for mounted volumes."""
    print("Creating data directories...")
    
    # Create base data directory if it doesn't exist
    data_dir = os.environ.get('DATA_FOLDER', './data')
    if not os.path.exists(data_dir):
        os.makedirs(data_dir, exist_ok=True)
    
    # Create Grafana provisioning directories
    grafana_dir = os.path.join(data_dir, 'grafana', 'provisioning')
    for subdir in ['datasources', 'dashboards', 'notifiers', 'plugins']:
        full_path = os.path.join(grafana_dir, subdir)
        if not os.path.exists(full_path):
            os.makedirs(full_path, exist_ok=True)
    
    print(f"Created data directories in {data_dir}")

def main():
    parser = argparse.ArgumentParser(description='Start the local AI and Supabase services.')
    parser.add_argument('--profile', choices=['cpu', 'gpu-nvidia', 'gpu-amd', 'none'], default='cpu',
                      help='Profile to use for Docker Compose (default: cpu)')
    parser.add_argument('--interactive', action='store_true', default=False,
                      help='Create .env file interactively with generated values')
    parser.add_argument('--use-example', action='store_true', default=True,
                      help='Create .env file from .env.example (default)')
    args = parser.parse_args()

    # Create .env file
    env_created = False
    if args.interactive:
        print("\nCreating .env file interactively. If you leave a field empty, the value from .env.example will be used.")
        env_created = create_interactive_env()
    elif args.use_example:
        print("\nCreating .env file from .env.example. Default values will be used for empty fields.")
        env_created = create_env_from_example()
    
    # Check if we should continue
    if not env_created or not os.path.exists('.env'):
        print("Error: No .env file created. Exiting.")
        sys.exit(1)
        
    # Check if the user wants to proceed with starting services
    proceed = input("\nDo you want to start services now? (y/n): ").lower()
    if proceed != 'y':
        print("Exiting without starting services. Run this script again when ready.")
        sys.exit(0)
    
    # Initialize monitoring
    initialize_monitoring()
    
    # Create necessary data directories
    create_data_directories()
    
    # Clone Supabase repo and prepare environment
    clone_supabase_repo()
    if not prepare_supabase_env():
        print("Error preparing Supabase environment. Exiting.")
        sys.exit(1)
    
    # Generate SearXNG secret key and check docker-compose.yml
    generate_searxng_secret_key()
    check_and_fix_docker_compose_for_searxng()
    
    stop_existing_containers()
    
    # Start Supabase first
    start_supabase()
    
    # Give Supabase some time to initialize
    print("Waiting for Supabase to initialize...")
    time.sleep(10)
    
    # Then start the local AI services
    start_local_ai(args.profile)

if __name__ == "__main__":
    main()

# Created and maintained by Z4Y